================================================================================
AGENT: learner_research_agent
================================================================================

SYSTEM PROMPT:
You are operating inside a strict automated pipeline.

CRITICAL OUTPUT RULES:
- You MUST return ONLY a single valid JSON object.
- Do NOT include markdown fences (```), code blocks, backticks, headings outside JSON, or any commentary.
- Do NOT wrap JSON in additional text.
- All strings must use double quotes.
- No trailing commas.
- The JSON must parse successfully with a standard JSON parser.

CONTENT RULES:
- Use ONLY facts present in the provided prompt sections (BUSINESS_BRIEF, SME_NOTES, CURRENT_STATE).
- If required info is missing or ambiguous, add questions to open_questions.
- Do NOT invent, assume, or hallucinate details.
- deliverable_markdown must be detailed, professional Markdown content (inside the JSON string).
- updated_state must be consistent with deliverable_markdown.
- open_questions must be an array of strings.

QUALITY BAR:
- Write at senior industry benchmark level.
- Make outputs precise, measurable, and execution-ready.

Before responding:
1. Validate your output is valid JSON.
2. Validate required keys exist: deliverable_markdown, updated_state, open_questions.
3. Output ONLY the JSON object.
```markdown
# Learner Research Agent (Learner Analysis & Behavior Insight)

## Role

You are the Learner Research Agent.  
You operate as a behavioral researcher and learning experience analyst.

Your job is to expand the Strategy Lead’s work by deeply understanding the learner:
- motivations
- barriers
- work context
- cognitive load
- emotional factors
- environmental constraints

You do not redesign the strategy.  
You enrich it with learner intelligence so that learning design decisions are grounded in real human behavior.

---

## Inputs You Will Receive

- STRATEGY_OUTPUT (from Strategy Lead)
- CURRENT_STATE (json)
- BUSINESS_BRIEF (markdown)
- SME_NOTES (markdown)

---

## What You Must Produce

Return one valid JSON object containing:

1. `deliverable_markdown`  
   A professional learner research summary.

2. `updated_state`  
   Structured learner intelligence added to system state.

3. `open_questions`  
   Clarifications needed to reduce learner uncertainty.

---

## Research Objectives

You must:

- Identify learner personas or segments
- Understand learner motivation
- Identify cognitive, emotional, and environmental barriers
- Describe real-world application conditions
- Identify friction points for adoption and behavior change

---

## Research Tasks

1. Define 1–3 learner personas or archetypes  
   Include:
   - role
   - experience level
   - confidence
   - learning maturity

2. Identify learner motivations  
   - intrinsic and extrinsic

3. Identify learner barriers  
   - time
   - trust
   - cognitive load
   - habits
   - environmental constraints

4. Describe real-world application context  
   - when learning is applied
   - what pressure exists
   - what tools are available

5. Identify emotional and behavioral risks  
   - fear of failure
   - resistance to change
   - AI skepticism
   - accountability concerns

6. Identify engagement design implications  
   - what will help adoption
   - what will cause drop-off

---

## Output Format Rules (STRICT)

Return ONLY valid JSON.

```json
{
  "deliverable_markdown": "string",
  "updated_state": {},
  "open_questions": []
}


CURRENT_STATE (JSON):
{
  "inputs": {
    "business_brief": "# Business Brief\n\n## Program name\nAI Adoption for Operations Managers\n\n## Who is this for? (Audience)\nPlant operations managers responsible for monitoring performance dashboards and making daily production decisions. Most have limited experience using AI tools.\n\n## What is the performance problem?\nManagers ignore AI dashboards and rely on manual reporting or gut instinct instead of data-driven insights.\n\n## What does success look like?\nManagers regularly consult AI dashboards, interpret trends correctly, and adjust production plans based on AI recommendations.\n\n## Business outcomes / KPIs\n- Increased dashboard usage\n- Faster decision-making\n- Reduced production inefficiencies\n\n## Constraints\n- Training must be under 45 minutes\n- Must work on desktop and tablet\n- No prior AI knowledge assumed\n\n## Required topics\n- What AI dashboards show\n- How to interpret insights\n- How to trust AI recommendations\n\n## Out of scope\n- How AI models are built\n- Coding or data science concepts\n\n## Deliverable format\nSelf-paced eLearning course with short modules and scenario-based questions\n",
    "sme_notes": "# SME Notes\n\n## Must-be-true facts\nAI dashboards update every 5 minutes and pull from production line sensors.\n\n## Terminology\nAI dashboard, predictive alert, performance trend.\n\n## Policies / compliance\nNo sensitive data may be exported outside the company.\n\n## Common mistakes learners make\nThey assume AI predictions are guesses and ignore them.\n\n## Real examples / scenarios\nA dashboard shows a drop in throughput that predicts a machine failure in 2 hours.\n"
  },
  "strategy": {
    "status": "complete",
    "program_name": "AI Adoption for Operations Managers",
    "program_purpose": "Equip plant operations managers to routinely consult AI dashboards, accurately interpret production insights, and take timely data-driven action \u2014 replacing reliance on manual reporting and gut instinct.",
    "target_audience": {
      "primary_role": "Plant operations managers",
      "work_context": "Manufacturing / production floor; time-pressured daily decisions",
      "learning_environment": "Self-paced eLearning on desktop and tablet",
      "max_training_time_minutes": 45,
      "devices": [
        "desktop",
        "tablet"
      ],
      "prior_ai_knowledge": "none",
      "motivation_factors": [
        "faster decisions",
        "peer adoption",
        "management expectation"
      ],
      "resistance_risks": [
        "distrust of AI predictions",
        "comfort with manual processes",
        "fear of technology replacing judgment",
        "time pressure"
      ]
    },
    "performance_problem": {
      "current_behaviors": [
        "Managers bypass AI dashboards or check them infrequently",
        "Decisions based on manual reports, historical patterns, or intuition",
        "Predictive alerts dismissed or ignored",
        "Dashboard insights misinterpreted or not acted upon"
      ],
      "root_causes": [
        "Lack of understanding of dashboard content and data sources",
        "Distrust of AI predictions \u2014 perceived as unreliable guesses",
        "No established workflow integrating dashboard consultation",
        "Insufficient skills to interpret trends, alerts, and recommendations",
        "Comfort with legacy manual reporting"
      ],
      "business_impact": [
        "Delayed response to production anomalies",
        "Increased downtime and inefficiency",
        "Underutilization of AI technology investment",
        "Slower decision-making cycles"
      ]
    },
    "desired_performance": {
      "observable_behaviors": [
        "Consult AI dashboard at start of each shift and before production adjustments",
        "Correctly identify and describe key dashboard indicators",
        "Distinguish routine fluctuations from actionable predictive alerts",
        "Adjust production plans based on AI recommendations with documented rationale",
        "Escalate high-severity predictive alerts appropriately"
      ],
      "performance_standards": [
        "Dashboard consulted minimum once per shift",
        "Action taken within decision window indicated by alert",
        "80% interpretation accuracy on assessment scenarios"
      ]
    },
    "learning_outcomes": [
      {
        "id": "LO1",
        "outcome": "Describe what the AI dashboard displays and where its data originates",
        "rationale": "Managers understand they are viewing real-time sensor data, not speculative outputs"
      },
      {
        "id": "LO2",
        "outcome": "Identify and differentiate the three key dashboard elements: performance trends, predictive alerts, and throughput indicators",
        "rationale": "Managers can read the dashboard without confusion"
      },
      {
        "id": "LO3",
        "outcome": "Interpret a predictive alert by explaining what it predicts, the confidence basis, and the recommended action window",
        "rationale": "Managers treat alerts as actionable intelligence rather than guesses"
      },
      {
        "id": "LO4",
        "outcome": "Evaluate an AI recommendation against current operational context to decide whether to act, modify, or escalate",
        "rationale": "Managers integrate AI insights with operational expertise"
      },
      {
        "id": "LO5",
        "outcome": "Demonstrate a complete decision workflow: consult dashboard, interpret signals, decide on action, and document rationale",
        "rationale": "Dashboard-informed decision-making becomes a repeatable habit"
      }
    ],
    "program_structure": {
      "format": "Self-paced eLearning with short modules and scenario-based questions",
      "total_duration_minutes": 45,
      "modules": [
        {
          "module_number": 1,
          "title": "Understanding Your AI Dashboard",
          "focus": "What the dashboard shows; data sources; update frequency",
          "estimated_duration_minutes": 10,
          "outcomes_addressed": [
            "LO1"
          ]
        },
        {
          "module_number": 2,
          "title": "Reading the Signals",
          "focus": "Key elements \u2014 trends, alerts, indicators; how to differentiate them",
          "estimated_duration_minutes": 10,
          "outcomes_addressed": [
            "LO2"
          ]
        },
        {
          "module_number": 3,
          "title": "Interpreting Predictive Alerts",
          "focus": "What predictions mean; sensor-data basis; action windows",
          "estimated_duration_minutes": 10,
          "outcomes_addressed": [
            "LO3"
          ]
        },
        {
          "module_number": 4,
          "title": "Making Data-Driven Decisions",
          "focus": "Evaluating recommendations; integrating with operational judgment; when to escalate",
          "estimated_duration_minutes": 15,
          "outcomes_addressed": [
            "LO4",
            "LO5"
          ]
        }
      ]
    },
    "assessment_strategy": {
      "formative": "Scenario-based check questions embedded within each module",
      "summative": "Capstone scenario requiring dashboard consultation, signal interpretation, decision-making, and rationale justification",
      "success_threshold": "80% accuracy on scenario-based assessments"
    },
    "kpi_alignment": {
      "increased_dashboard_usage": "Outcomes LO1 and LO5 build understanding and habit; Module 4 integrates dashboard into decision workflow",
      "faster_decision_making": "Outcomes LO3 and LO4 teach efficient interpretation and action; scenario practice builds fluency",
      "reduced_production_inefficiencies": "Outcome LO4 ensures AI recommendations are evaluated and acted upon within appropriate time windows"
    },
    "design_principles": [
      "Performance-first: every module connects to an on-the-job behavior",
      "Scenario-based: realistic production scenarios as primary instructional vehicle",
      "Trust-building: explicitly address misconception that AI predictions are guesses",
      "Constraint-aware: desktop and tablet compatible; no data export",
      "Modular: self-contained modules for flexible completion across shifts"
    ],
    "terminology": [
      "AI dashboard",
      "predictive alert",
      "performance trend"
    ],
    "compliance_notes": [
      "No sensitive data may be exported outside the company"
    ],
    "out_of_scope": [
      "How AI models are built",
      "Coding or data science concepts"
    ]
  },
  "research": {},
  "curriculum": {},
  "module_designs": [],
  "assessments": [],
  "storyboards": [],
  "qa": {},
  "change_plan": {},
  "ops_metadata": {}
}

BUSINESS_BRIEF (markdown):
# Business Brief

## Program name
AI Adoption for Operations Managers

## Who is this for? (Audience)
Plant operations managers responsible for monitoring performance dashboards and making daily production decisions. Most have limited experience using AI tools.

## What is the performance problem?
Managers ignore AI dashboards and rely on manual reporting or gut instinct instead of data-driven insights.

## What does success look like?
Managers regularly consult AI dashboards, interpret trends correctly, and adjust production plans based on AI recommendations.

## Business outcomes / KPIs
- Increased dashboard usage
- Faster decision-making
- Reduced production inefficiencies

## Constraints
- Training must be under 45 minutes
- Must work on desktop and tablet
- No prior AI knowledge assumed

## Required topics
- What AI dashboards show
- How to interpret insights
- How to trust AI recommendations

## Out of scope
- How AI models are built
- Coding or data science concepts

## Deliverable format
Self-paced eLearning course with short modules and scenario-based questions


SME_NOTES (markdown):
# SME Notes

## Must-be-true facts
AI dashboards update every 5 minutes and pull from production line sensors.

## Terminology
AI dashboard, predictive alert, performance trend.

## Policies / compliance
No sensitive data may be exported outside the company.

## Common mistakes learners make
They assume AI predictions are guesses and ignore them.

## Real examples / scenarios
A dashboard shows a drop in throughput that predicts a machine failure in 2 hours.


INSTRUCTIONS:
- Return ONLY valid JSON
- Required keys: deliverable_markdown, updated_state, open_questions
- No extra commentary outside the JSON object
================================================================================